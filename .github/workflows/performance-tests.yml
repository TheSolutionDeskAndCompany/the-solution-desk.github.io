name: Performance Tests

on:
  push:
    branches: [ main, backend-main ]
    paths:
      - 'backend/**'
      - '.github/workflows/performance-tests.yml'
  pull_request:
    branches: [ main, backend-main ]
    paths:
      - 'backend/**'
      - '.github/workflows/performance-tests.yml'
  workflow_dispatch:  # Allow manual triggering

jobs:
  performance:
    runs-on: ubuntu-latest
    needs: test  # Depend on the test job from backend.yml
    defaults:
      run:
        working-directory: ./backend
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Install k6
        uses: grafana/k6-action@v0.4.0
        with:
          installargs: "--ignore-scripts"

      - name: Run k6 performance tests
        id: k6
        run: |
          # Set environment variables for test configuration
          export K6_PUBLIC_API_URL=${{ github.event.inputs.api_url || 'http://localhost:5000' }}
          export K6_DURATION=${{ github.event.inputs.duration || '30s' }}
          export K6_VUS=${{ github.event.inputs.vus || '10' }}
          
          # Run the performance test scripts
          echo "Running k6 performance tests against: $K6_PUBLIC_API_URL"
          mkdir -p test-results
          
          # Run auth performance test
          echo "Running auth performance test..."
          k6 run --out json=test-results/auth-performance.json \
                --summary-export=test-results/auth-summary.json \
                tests/load-tests/auth-performance.js
          
          # Run API performance test
          echo "Running API performance test..."
          k6 run --out json=test-results/api-performance.json \
                --summary-export=test-results/api-summary.json \
                tests/load-tests/api-performance.js
          
          # Generate markdown report
          echo "Generating test report..."
          echo "# Performance Test Results" > test-results/report.md
          echo "## Auth Performance" >> test-results/report.md
          echo '```' >> test-results/report.md
          jq -r '.metrics | to_entries[] | "\(.key): \(.value.values.rate) reqs/s (p95: \(.value.values["p(95)"]))"' test-results/auth-summary.json >> test-results/report.md
          echo '```' >> test-results/report.md
          
          echo "## API Performance" >> test-results/report.md
          echo '```' >> test-results/report.md
          jq -r '.metrics | to_entries[] | "\(.key): \(.value.values.rate) reqs/s (p95: \(.value.values["p(95)"]))"' test-results/api-summary.json >> test-results/report.md
          echo '```' >> test-results/report.md
          
          # Check for test failures
          if grep -q "failed" test-results/*-summary.json; then
            echo "PERF_TEST_RESULT=failure" >> $GITHUB_OUTPUT
          else
            echo "PERF_TEST_RESULT=success" >> $GITHUB_OUTPUT
          fi
        continue-on-error: true  # Don't fail the job yet, we'll handle it after uploading artifacts

      - name: Upload test results
        uses: actions/upload-artifact@v3
        with:
          name: k6-test-results
          path: |
            backend/test-results/**/*.json
            backend/test-results/report.md
          retention-days: 90

      - name: Comment on PR with results
        if: github.event_name == 'pull_request' && steps.k6.outputs.PERF_TEST_RESULT
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            const report = fs.readFileSync('backend/test-results/report.md', 'utf8');
            
            const maxBodyLength = 65536;  // GitHub's maximum comment length
            const truncatedReport = report.length > maxBodyLength 
              ? report.substring(0, maxBodyLength - 100) + '\n... (report truncated)'
              : report;
            
            await github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: `## ðŸš€ Performance Test Results\n\n${truncatedReport}\n\n[View full test artifacts](https://github.com/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId})`
            });
            
            // If tests passed, check for and close any related performance issues
            if (steps.k6.outputs.PERF_TEST_RESULT === 'success') {
              const branchName = process.env.GITHUB_HEAD_REF || process.env.GITHUB_REF_NAME || 'main';
              
              // Find open performance issues for this branch
              const { data: issues } = await github.rest.issues.listForRepo({
                owner: context.repo.owner,
                repo: context.repo.repo,
                state: 'open',
                labels: 'performance,automated',
                sort: 'created',
                direction: 'desc'
              });
              
              const branchIssues = issues.filter(issue => 
                issue.title.includes('Performance Test Failure') && 
                issue.body.includes(`Branch: ${branchName}`)
              );
              
              // Close any open issues for this branch
              for (const issue of branchIssues) {
                await github.rest.issues.update({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  issue_number: issue.number,
                  state: 'closed',
                  state_reason: 'completed'
                });
                
                await github.rest.issues.createComment({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  issue_number: issue.number,
                  body: `## âœ… Performance Issue Resolved\n\nThe performance tests are now passing on branch \`${branchName}\`.\n\n**Run:** [${process.env.GITHUB_RUN_ID}](https://github.com/${process.env.GITHUB_REPOSITORY}/actions/runs/${process.env.GITHUB_RUN_ID})\n\n---\n*This is an automated message*`
                });
              }
            }

      - name: Create GitHub Issue for Failed Tests
        if: failure() && github.event_name != 'pull_request'
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            const path = require('path');
            
            // Get the test report
            let report = 'Performance test report not available';
            try {
              report = fs.readFileSync('backend/test-results/report.md', 'utf8');
            } catch (e) {
              console.error('Failed to read test report:', e);
            }
            
            // Get the branch name
            const branchName = process.env.GITHUB_REF_NAME || 'main';
            const runId = process.env.GITHUB_RUN_ID;
            const runUrl = `https://github.com/${process.env.GITHUB_REPOSITORY}/actions/runs/${runId}`;
            
            // Check for existing open issues with the same title
            const { data: issues } = await github.rest.issues.listForRepo({
              owner: context.repo.owner,
              repo: context.repo.repo,
              state: 'open',
              labels: 'performance,automated',
              sort: 'created',
              direction: 'desc'
            });
            
            const existingIssue = issues.find(issue => 
              issue.title.includes('Performance Test Failure') && 
              issue.body.includes(`Branch: ${branchName}`) &&
              (Date.now() - new Date(issue.created_at).getTime()) < (24 * 60 * 60 * 1000) // Within 24 hours
            );
            
            if (existingIssue) {
              console.log(`Updating existing issue #${existingIssue.number}`);
              // Update existing issue with new failure
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: existingIssue.number,
                body: `## ðŸ”„ New Test Failure Detected\n\n**Run:** [${runId}](${runUrl})\n**Branch:** ${branchName}\n\n${report}\n\n---\n*This is an automated message*`
              });
              
              // Reopen if closed
              if (existingIssue.state === 'closed') {
                await github.rest.issues.update({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  issue_number: existingIssue.number,
                  state: 'open'
                });
              }
            } else {
              // Create new issue
              await github.rest.issues.create({
                owner: context.repo.owner,
                repo: context.repo.repo,
                title: `Performance Test Failure on ${branchName} - ${new Date().toISOString().split('T')[0]}`,
                body: `# ðŸš¨ Performance Test Failure\n\n**Branch:** ${branchName}\n**Run:** [${runId}](${runUrl})\n\n## Test Results\n\n${report}\n\n## Next Steps\n\n1. Review the performance test results above\n2. Check the [CI run](${runUrl}) for more details\n3. Investigate any performance regressions\n4. Close this issue when resolved\n\n---\n*This is an automated issue created by the CI/CD pipeline*`,
                labels: ['performance', 'bug', 'automated'],
                assignees: ['@TheSolutionDeskAndCompany/backend']
              });
            }

      - name: Fail if performance tests failed
        if: steps.k6.outputs.PERF_TEST_RESULT == 'failure'
        run: exit 1
